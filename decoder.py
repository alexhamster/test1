
import os

BASEDIR_PATH = os.path.dirname(__file__)
SRC_DIR = os.path.join(BASEDIR_PATH, "./tokenized")
DST_DIR = os.path.join(BASEDIR_PATH, "./decoded")

import os
import json
from pathlib import Path
from transformers import AutoTokenizer

# ðŸ›ˆ ÐŸÐ¾Ð¼ÐµÐ½ÑÐ¹ Ð½Ð° ÑÐ²Ð¾Ð¸ Ð¿ÑƒÑ‚Ð¸

tokenizer = AutoTokenizer.from_pretrained(
    "google/gemma-3-4b-it",
    use_fast=False
)

def decode_gemma_file(path: Path):
    """Ð§Ð¸Ñ‚Ð°ÐµÑ‚ Ñ„Ð°Ð¹Ð» Ñ JSON-ÑÑ‚Ñ€Ð¾ÐºÐ°Ð¼Ð¸ Ð¸ Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ ÑÐ¿Ð¸ÑÐ¾Ðº Ð´ÐµÐºÐ¾Ð´Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ñ… Ñ‚ÐµÐºÑÑ‚Ð¾Ð²."""
    texts = []
    with path.open("r", encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if not line:
                continue  # Ð¿Ñ€Ð¾Ð¿ÑƒÑÐºÐ°ÐµÐ¼ Ð¿ÑƒÑÑ‚Ñ‹Ðµ ÑÑ‚Ñ€Ð¾ÐºÐ¸
            obj = json.loads(line)
            input_ids = obj["input_ids"]
            text = tokenizer.decode(input_ids, skip_special_tokens=True)
            texts.append(text)
    return texts

def process_directory(src_dir: Path, dst_dir: Path):
    """
    Ð ÐµÐºÑƒÑ€ÑÐ¸Ð²Ð½Ð¾ Ð¾Ð±Ñ…Ð¾Ð´Ð¸Ñ‚ src_dir, Ð´ÐµÐºÐ¾Ð´Ð¸Ñ€ÑƒÐµÑ‚ ÐºÐ°Ð¶Ð´Ñ‹Ð¹ Ñ„Ð°Ð¹Ð»
    Ð¸ Ð·ÐµÑ€ÐºÐ°Ð»ÑŒÐ½Ð¾ ÑÐ¾Ñ…Ñ€Ð°Ð½ÑÐµÑ‚ Ð² dst_dir.
    """
    for root, dirs, files in os.walk(src_dir):
        root_path = Path(root)
        for fname in files:
            src_file = root_path / fname

            # Ð¾Ñ‚Ð½Ð¾ÑÐ¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¹ Ð¿ÑƒÑ‚ÑŒ Ð¾Ñ‚ ÐºÐ¾Ñ€Ð½Ñ Ð²Ñ…Ð¾Ð´Ð½Ð¾Ð¹ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸Ð¸
            rel_path = src_file.relative_to(src_dir)
            # Ð¿ÑƒÑ‚ÑŒ Ðº Ð²Ñ‹Ñ…Ð¾Ð´Ð½Ð¾Ð¼Ñƒ Ñ„Ð°Ð¹Ð»Ñƒ (Ð·ÐµÑ€ÐºÐ°Ð»ÑŒÐ½Ð°Ñ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð° ÐºÐ°Ñ‚Ð°Ð»Ð¾Ð³Ð¾Ð²)
            dst_file = (dst_dir / rel_path).with_suffix(".md")

            # ÑÐ¾Ð·Ð´Ð°Ñ‘Ð¼ Ð¿Ð¾Ð´Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸ÑŽ, ÐµÑÐ»Ð¸ ÐµÑ‘ ÐµÑ‰Ñ‘ Ð½ÐµÑ‚
            dst_file.parent.mkdir(parents=True, exist_ok=True)

            # Ð´ÐµÐºÐ¾Ð´Ð¸Ñ€ÑƒÐµÐ¼ ÑÐ¾Ð´ÐµÑ€Ð¶Ð¸Ð¼Ð¾Ðµ Ñ„Ð°Ð¹Ð»Ð°
            try:
                texts = decode_gemma_file(src_file)
            except Exception as e:
                print(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐµ {src_file}: {e}")
                continue

            # ÑÐ¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð´ÐµÐºÐ¾Ð´Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹ Ñ‚ÐµÐºÑÑ‚
            # Ð·Ð´ÐµÑÑŒ: Ð¾Ð´Ð¸Ð½ Ð¿Ñ€Ð¸Ð¼ÐµÑ€ = Ð¾Ð´Ð¸Ð½ Ð±Ð»Ð¾Ðº, Ñ€Ð°Ð·Ð´ÐµÐ»Ñ‘Ð½Ð½Ñ‹Ð¹ Ð¿ÑƒÑÑ‚Ð¾Ð¹ ÑÑ‚Ñ€Ð¾ÐºÐ¾Ð¹
            with dst_file.open("w", encoding="utf-8") as out_f:
                for i, t in enumerate(texts):
                    if i > 0:
                        out_f.write("\n\n")  # Ð¿ÑƒÑÑ‚Ð°Ñ ÑÑ‚Ñ€Ð¾ÐºÐ° Ð¼ÐµÐ¶Ð´Ñƒ Ð¿Ñ€Ð¸Ð¼ÐµÑ€Ð°Ð¼Ð¸
                    out_f.write(t)

            print(f"Ð“Ð¾Ñ‚Ð¾Ð²Ð¾: {src_file} -> {dst_file}")

if __name__ == "__main__":
    process_directory(SRC_DIR, DST_DIR)
